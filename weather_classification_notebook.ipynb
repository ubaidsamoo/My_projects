{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43a1fe9a",
   "metadata": {},
   "source": [
    "# Weather Classification with Decision Trees\n",
    "\n",
    "This notebook performs a supervised classification pipeline to predict the weather condition from meteorological features. It includes data loading, exploratory analysis, preprocessing, model training with Decision Trees (varying max_depth), and analysis of overfitting vs generalization.\n",
    "\n",
    "**Data source note:** No 'weather.csv' found. Synthetic dataset created for demonstration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d142be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (this cell replicates what was run in the notebook environment)\n",
    "import pandas as pd\n",
    "df = pd.read_csv('weather.csv') if __import__('os').path.exists('weather.csv') else None\n",
    "print('df is None -> dataset file not found in working directory' if df is None else 'Loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750603d0",
   "metadata": {},
   "source": [
    "## Data Loading & Overview\n",
    "\n",
    "- Show top records and describe the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff64edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('weather.csv') if __import__('os').path.exists('weather.csv') else None\n",
    "\n",
    "if df is None:\n",
    "    print('No weather.csv found in working directory. This notebook used a synthetic dataset created programmatically.')\n",
    "else:\n",
    "    display(df.head())\n",
    "    print('\\nInfo:')\n",
    "    df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e844dcc",
   "metadata": {},
   "source": [
    "## Exploratory Analysis\n",
    "\n",
    "- Distribution of the target classes and simple quality checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30a659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head())\n",
    "print('\\nValue counts for target:')\n",
    "print(df['Weather'].value_counts())\n",
    "\n",
    "print('\\nMissing values per column:')\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print('\\nNumber of duplicate rows:')\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd73c1c",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "- Separate features and target, perform train-test split, and set up preprocessing pipelines for numeric and categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397c0d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X = df.drop(columns=['Weather'])\n",
    "y = df['Weather']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)\n",
    "\n",
    "cat_cols = X.select_dtypes(include=['object','category']).columns.tolist()\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print('Numeric cols:', num_cols)\n",
    "print('Categorical cols:', cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5bc8de",
   "metadata": {},
   "source": [
    "## Modeling — Decision Trees\n",
    "\n",
    "- Train Decision Tree models with multiple `max_depth` values (1–9 and None). Record train and test accuracy for each configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ee5346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')),('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, num_cols),('cat', categorical_transformer, cat_cols)])\n",
    "\n",
    "results = []\n",
    "depths = list(range(1,10)) + [None]\n",
    "for d in depths:\n",
    "    clf = Pipeline(steps=[('pre', preprocessor),('clf', DecisionTreeClassifier(max_depth=d, random_state=42))])\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_tr = clf.predict(X_train)\n",
    "    y_te = clf.predict(X_test)\n",
    "    results.append({'max_depth': d,'train_acc': accuracy_score(y_train, y_tr),'test_acc': accuracy_score(y_test, y_te)})\n",
    "\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daac495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,5))\n",
    "x_labels = [str(d) for d in depths]\n",
    "plt.plot(x_labels, results_df['train_acc'], marker='o', label='Train accuracy')\n",
    "plt.plot(x_labels, results_df['test_acc'], marker='o', label='Test accuracy')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Decision Tree: train vs test accuracy by max_depth')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95091adb",
   "metadata": {},
   "source": [
    "## Analysis & Conclusion\n",
    "\n",
    "- Compare how model depth affects overfitting/generalization.\n",
    "- State which depth performs best and why.\n",
    "\n",
    "(See the test accuracy column in results to determine best depth. A shallow tree may underfit; a very deep tree may overfit — choose a depth with high test accuracy and minimal gap to train accuracy.)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
